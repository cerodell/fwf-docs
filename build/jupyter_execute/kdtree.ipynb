{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "potential-activation",
   "metadata": {},
   "source": [
    "\n",
    "# Datasets\n",
    "\n",
    "The Datasets are divided up by their model domain"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "formal-activation",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Model Domains\n",
    "\n",
    "The FWF model resolves the FWI System/ FBP System in the D02 (12 km) and D03 (4 km) at 55 hour forecast horizon.\n",
    "\n",
    "![title](_static/images/fwf-model-domains.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "neutral-rabbit",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "### Description\n",
    "\n",
    "For each domain there are two `.nc` (netcdf) files generated, four total datasets each day.\n",
    "\n",
    "**Domain: d02 (12 km)**\n",
    "-  `fwf-hourly-d02-YYYYMMDDHH.nc`\n",
    "    - File Size: ~ 780M\n",
    "    - File Dimensions: (time: 55, south_north: 417, west_east: 627)\n",
    "-  `fwf-daily-d02-YYYYMMDDHH.nc`\n",
    "    - File Size: ~ 16M\n",
    "    - File Dimensions: (time: 2, south_north: 417, west_east: 627)\n",
    "\n",
    "\n",
    "**Domain: d03 (4 km)**\n",
    "-  `fwf-hourly-d03-YYYYMMDDHH.nc`\n",
    "    - File Size:  ~ 1.7G\n",
    "    - File Dimensions: (time: 55, south_north: 840, west_east: 642)\n",
    "-  `fwf-daily-d03-YYYYMMDDHH.nc`\n",
    "    - File Size: ~ 30M\n",
    "    - File Dimensions: (time: 2, south_north: 840, west_east: 642)\n",
    "\n",
    "\n",
    "### Dataset Variables\n",
    "\n",
    "Regardless of Domain, each dataset hourly/daily contain the following variables."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "serious-machine",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "| Hourly Dataset <br> `fwf-hourly-<domain>-YYYYMMDDHH.nc`  | Daily Dataset <br> `fwf-daily-<domain>--YYYYMMDDHH.nc`  | \n",
    "| --------------------------- | ------------------------- |\n",
    "|**Time**: Hourly UTC  |**Time**: Noon Local for that Day |\n",
    "|**XLAT**: Degrees Latitude  |**XLAT**: Degrees Latitude|\n",
    "|**XLON**: Degrees Longitude  |**XLON**: Degrees Longitude|\n",
    "|**F**: Fine Fuel Moisture Code  |**P**: Duff Moisture Code  |\n",
    "|**m_o**: Fine Fuel Moisture Content  |**D**: Drought Moisture Code  |\n",
    "|**R**: Initial Spread Index   |**U**: Build Up Index   |\n",
    "|**S**: Fire Weather Index|**T**: 2 meter Temperature C |\n",
    "|**DSR**: Daily Severity Rating  | **TD**: 2 meter Dew Point Temperature C |\n",
    "|**FMC**: Foliar Moisture Content %  | **H**: 2 meter Relative Humdity %  |\n",
    "|**SFC**: Surface Fuel Consumption kg m^{-2}  | **W**: 10 meter Wind Speed km/h |\n",
    "|**TFC**: Total Fuel Consumption kg m^{-2} | **WD**: 10 meter Wind Direction deg  |\n",
    "|**ROS**: Rate of Spread m min^{-1}  | **r_o**: Total Accumulated Precipitation mm  |\n",
    "|**CFB**: Crown Fraction Burned % | **r_o_tomorrow**: Carry Over Precipitation mm  |\n",
    "|**HFI**: Head Fire Intensity  kW m^{-1} |**SNOWC**: Flag Inidicating Snow <br> Cover (1 for Snow Cover) Snow Depth m   |\n",
    "|**T**: 2 meter Temperature C  |   |\n",
    "|**TD**: 2 meter Dew Point Temperature C  | |\n",
    "|**H**: 2 meter Relative Humdity % |  |\n",
    "|**W**: 10 meter Wind Speed km/h  |  |\n",
    "|**WD**: 10 meter Wind Direction deg  |   |\n",
    "|**U10**:  U Component of Wind at 10 meter m/s  | |\n",
    "|**V10**: V Component of Wind at 10 meter m/s  |   |\n",
    "|**r_o**: Total Accumulated Precipitation mm  |   |\n",
    "|**r_o_hourly**: Hourly Accumulated Precipitation mm  |  |\n",
    "|**SNW**: Total Accumulated Snow cm  |   |\n",
    "|**SNOWH**: Physical Snow Depth m  |   |\n",
    "|**SNOWC**: Flag Indicating Snow <br> Cover (1 for Snow Cover) Snow Depth m  |   |"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "protecting-timothy",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "## Working with\n",
    "\n",
    "Suggest using [xarray](http://xarray.pydata.org/en/stable/) to open and work with data.\n",
    "\n",
    "An example of how to open and view "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "textile-spray",
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'context'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-1-81e43e82d236>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mcontext\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mxarray\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mxr\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0mcontext\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mdata_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfwf_dir\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'context'"
     ]
    }
   ],
   "source": [
    "import context\n",
    "import numpy as np\n",
    "import xarray as xr\n",
    "from context import data_dir, fwf_dir\n",
    "\n",
    "forecast_date = '2021051006'  ## \"YYYYMMDDHH\"\n",
    "domain        = 'd02'         ## or 'd03'\n",
    "name \t        = 'hourly'      ## or 'daily'\n",
    "\n",
    "## file directory\n",
    "filein = str(fwf_dir) + f\"/fwf-{name}-{domain}-{forecast_date}.nc\"\n",
    "\n",
    "## open dataset\n",
    "ds = xr.open_dataset(filein)\n",
    "\n",
    "## chunk data to dask.arrays \n",
    "ds = ds.chunk(chunks=\"auto\")\n",
    "ds = ds.unify_chunks()\n",
    "# NOTE this is not needed. Arrays will be either numpy float32 or objects\n",
    "\n",
    "## Example: look at variable F (Fine Fuels Moisture Code)\n",
    "print(ds.F)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "pediatric-doctrine",
   "metadata": {},
   "source": [
    "# How to search the FWF data set by locations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "norman-milton",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "import context\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import xarray as xr\n",
    "from sklearn.neighbors import KDTree\n",
    "\n",
    "\n",
    "from pathlib import Path\n",
    "\n",
    "from context import data_dir, fwf_dir\n",
    "from datetime import datetime, date, timedelta"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "normal-distance",
   "metadata": {},
   "source": [
    "## Set Up\n",
    "Define forecast date, domain and set paths to dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "tamil-operations",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "forecast_date = '2021051006'  ## \"YYYYMMDDHH\"\n",
    "domain        = 'd02'         ## or 'd03'\n",
    "name \t        = 'hourly'      ## or 'daily'\n",
    "\n",
    "## set path to gridded forecast dataset\n",
    "filein = str(fwf_dir) + f\"/fwf-{name}-{domain}-{forecast_date}.nc\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "assigned-republican",
   "metadata": {},
   "source": [
    "Open forecast dataset and print "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "failing-stupid",
   "metadata": {},
   "outputs": [],
   "source": [
    "## open forecast dataset\n",
    "ds = xr.open_dataset(filein)\n",
    "\n",
    "## take a look inside\n",
    "print(ds)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "clean-northern",
   "metadata": {
    "lines_to_next_cell": 0
   },
   "source": [
    "Load a data set of weather sation locations and look at the first four rows as an example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "separated-uniform",
   "metadata": {},
   "outputs": [],
   "source": [
    "## load a data set of weather sation locations\n",
    "df = pd.read_csv(str(data_dir) + \"/nrcan-wxstations.csv\", sep=\",\", usecols = ['wmo',\t'lat',\t'lon'])\n",
    "\n",
    "## look at the first four wxstation in dataframe as example\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fifth-constant",
   "metadata": {},
   "source": [
    "\n",
    "## Set up to build a kdtree"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "sublime-beauty",
   "metadata": {},
   "outputs": [],
   "source": [
    "## first, set path to store kdtree\n",
    "kdtree_dir = Path(str(data_dir) + \"/kdtree/\")\n",
    "\n",
    "## make directory if it doesn't exist \n",
    "kdtree_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "## now take gridded lats and long and convert to np arrays\n",
    "XLAT, XLONG = ds.XLAT.values, ds.XLONG.values\n",
    "\n",
    "## get shape of gridded domain\n",
    "shape = XLAT.shape\n",
    "print(shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "considerable-suspect",
   "metadata": {},
   "source": [
    "## Build a kdtree and save"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "logical-system",
   "metadata": {},
   "outputs": [],
   "source": [
    "try:\n",
    "  ## try and open kdtree for domain\n",
    "  fwf_tree, fwf_locs = pickle.load(open(str(kdtree_dir) + f'fwf_{domain}_tree.p', \"rb\"))\n",
    "  print('Found FWF Tree')\n",
    "except:\n",
    "  ## build a kd-tree for fwf domain if not found\n",
    "  print(\"Could not find FWF KDTree building....\")\n",
    "  ## create dataframe with columns of all lat/long in the domian...rows are cord pairs \n",
    "  fwf_locs = pd.DataFrame({\"XLAT\": XLAT.ravel(), \"XLONG\": XLONG.ravel()})\n",
    "  ## build kdtree\n",
    "  fwf_tree = KDTree(fwf_locs)\n",
    "  ## save tree\n",
    "  pickle.dump([fwf_tree, fwf_locs], open(str(kdtree_dir) + f'fwf_{domain}_tree.p', \"wb\"))\n",
    "  print(\"FWF KDTree built\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "expressed-cuisine",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "## Search the data\n",
    "With a built kdtree we can query the tree to find the nearest neighbor model grid to our locations of interest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "balanced-african",
   "metadata": {},
   "outputs": [],
   "source": [
    "## define empty list to append index of weather station locations\n",
    "south_north,  west_east, wmo = [], [], []\n",
    "## loop each weather station in dataframe\n",
    "for loc in df.itertuples(index=True, name='Pandas'):\n",
    "  ## arange wx station lat and long in a formate to query the kdtree\n",
    "  single_loc = np.array([loc.lat, loc.lon]).reshape(1, -1)\n",
    "\n",
    "  ## query the kdtree retuning the distacne of nearest neighbor and the index on the raveled grid\n",
    "  fwf_dist, fwf_ind = fwf_tree.query(single_loc, k=1)\n",
    "\n",
    "  ## set condition to pass on stations outside model domian \n",
    "  if fwf_dist > 0.1:\n",
    "    pass\n",
    "  else:\n",
    "    ## if condition passed reformate 1D index to 2D indexes\n",
    "    fwf_2D_ind = np.unravel_index(int(fwf_ind), shape)\n",
    "    ## append the indexes to lists\n",
    "    wmo.append(loc.wmo)\n",
    "    south_north.append(fwf_2D_ind[0])\n",
    "    west_east.append(fwf_2D_ind[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "handmade-chambers",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "outside-mouth",
   "metadata": {},
   "outputs": [],
   "source": [
    "## now the magic of xarray..convert lists of indexes to a dataarray with dimension wmo (weather staton)..this allows you to index and entire dataset \n",
    "south_north = xr.DataArray(np.array(south_north), dims= 'wmo', coords= dict(wmo = wmo))\n",
    "west_east = xr.DataArray(np.array(west_east), dims= 'wmo', coords= dict(wmo = wmo))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "modified-repository",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "korean-clark",
   "metadata": {},
   "outputs": [],
   "source": [
    "## index the entire dataset at the locations of interest leaving diemion time with new dimension wx stations\n",
    "ds_loc = ds.sel(south_north = south_north, west_east = west_east)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "progressive-smile",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "split-accident",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "outputs": [],
   "source": [
    "## print to see new time series dataset at every weather station location\n",
    "print(ds_loc)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "exempt-continuity",
   "metadata": {
    "lines_to_next_cell": 2
   },
   "source": [
    "\n",
    "## Data License\n",
    "[Creative Commons Attribution 4.0 International License.](https://creativecommons.org/licenses/by/4.0/)"
   ]
  }
 ],
 "metadata": {
  "jupytext": {
   "cell_metadata_filter": "-all",
   "main_language": "python",
   "notebook_metadata_filter": "-all"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}